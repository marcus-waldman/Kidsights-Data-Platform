"""
Insert Adult Anxiety Imputations into DuckDB

Reads Feather files generated by 12_impute_adult_anxiety.R
and inserts imputed/derived values into DuckDB tables.

This script handles 9 adult_anxiety variables:
{{PYTHON_VARIABLE_DESCRIPTIONS}}

Usage:
    python scripts/imputation/ne25/12b_insert_adult_anxiety.py
"""

import sys
from pathlib import Path
import pandas as pd

# Add project root to path
# CRITICAL: Use correct parent chain for your file location
# __file__ is scripts/imputation/ne25/12b_insert_adult_anxiety.py
# parent = ne25/, parent.parent = imputation/, parent.parent.parent = scripts/,
# parent.parent.parent.parent = project_root
project_root = Path(__file__).resolve().parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from python.db.connection import DatabaseManager
from python.imputation.config import get_study_config, get_table_prefix


def load_feather_files(feather_dir: Path, variable_name: str, n_imputations: int, required: bool = True):
    """
    Load Feather files for a single variable across all imputations

    Parameters
    ----------
    feather_dir : Path
        Directory containing Feather files
    variable_name : str
        Name of variable (e.g., "{{EXAMPLE_VARIABLE}}")
    n_imputations : int
        Number of imputations to load (M)
    required : bool
        If True, raise error if files not found. If False, return empty dict.

    Returns
    -------
    dict
        Dictionary mapping imputation_m to DataFrame
    """
    # Pattern: {variable}_m{m}.feather
    pattern = f"{variable_name}_m*.feather"
    feather_files = sorted(feather_dir.glob(pattern))

    if len(feather_files) == 0:
        if required:
            raise FileNotFoundError(
                f"No Feather files found for variable '{variable_name}' in {feather_dir}\\n"
                f"Expected pattern: {pattern}\\n"
                f"Run adult_anxiety imputation script first: scripts/imputation/ne25/12_impute_adult_anxiety.R"
            )
        else:
            print(f"  [WARN] No Feather files found for {variable_name}")
            return {}

    imputations = {}

    for f in feather_files:
        # Extract m from filename
        import re
        match = re.search(r'_m(\d+)$', f.stem)
        if not match:
            raise ValueError(f"Could not extract imputation number from filename: {f.name}")
        m = int(match.group(1))
        df = pd.read_feather(f)

        # Validate columns
        expected_cols = {'study_id', 'pid', 'record_id', 'imputation_m', variable_name}
        if not expected_cols.issubset(df.columns):
            raise ValueError(
                f"Missing columns in {f.name}. Expected: {expected_cols}, Got: {set(df.columns)}"
            )

        imputations[m] = df

    if len(imputations) != n_imputations:
        print(f"  [WARN] Expected {n_imputations} files, found {len(imputations)} for {variable_name}")

    return imputations


def create_adult_anxiety_tables(db: DatabaseManager, study_id: str):
    """
    Create database tables for adult_anxiety imputations

    Following pattern: separate table per variable with naming:
    {study_id}_imputed_{variable_name}

    Parameters
    ----------
    db : DatabaseManager
        Database connection manager
    study_id : str
        Study identifier (e.g., "ne25")
    """
    print(f"\\n[INFO] Creating adult_anxiety imputation tables...")

    table_prefix = get_table_prefix(study_id)

    with db.get_connection() as conn:
        # TODO: [DATA TYPE] Create table for each variable with appropriate data type
        # Common data types:
        # - INTEGER: For binary (0/1) or count variables
        # - DOUBLE: For continuous or Likert scale (0-3, 0-4, etc.)
        # - BOOLEAN: For true/false variables
        # - VARCHAR: For categorical variables (rare in imputation)


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_1" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_1" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_1_pid_record"
    ON "ne25_imputed_gad7_1" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_1_imputation_m"
    ON "ne25_imputed_gad7_1" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_2" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_2" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_2_pid_record"
    ON "ne25_imputed_gad7_2" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_2_imputation_m"
    ON "ne25_imputed_gad7_2" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_3" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_3" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_3_pid_record"
    ON "ne25_imputed_gad7_3" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_3_imputation_m"
    ON "ne25_imputed_gad7_3" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_4" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_4" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_4_pid_record"
    ON "ne25_imputed_gad7_4" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_4_imputation_m"
    ON "ne25_imputed_gad7_4" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_5" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_5" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_5_pid_record"
    ON "ne25_imputed_gad7_5" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_5_imputation_m"
    ON "ne25_imputed_gad7_5" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_6" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_6" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_6_pid_record"
    ON "ne25_imputed_gad7_6" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_6_imputation_m"
    ON "ne25_imputed_gad7_6" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_7" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_7" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_7_pid_record"
    ON "ne25_imputed_gad7_7" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_7_imputation_m"
    ON "ne25_imputed_gad7_7" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_total" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_total" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_total_pid_record"
    ON "ne25_imputed_gad7_total" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_total_imputation_m"
    ON "ne25_imputed_gad7_total" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_positive" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_positive" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_positive_pid_record"
    ON "ne25_imputed_gad7_positive" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_positive_imputation_m"
    ON "ne25_imputed_gad7_positive" (imputation_m);


        # Create indexes for query performance
        adult_anxiety_vars = [{{VARIABLE_NAMES_QUOTED_PYTHON}}]
        for var in adult_anxiety_vars:
            conn.execute(f"""
                CREATE INDEX IF NOT EXISTS idx_{table_prefix}_{var}_pid_record
                ON {table_prefix}_{var} (pid, record_id)
            """)
            conn.execute(f"""
                CREATE INDEX IF NOT EXISTS idx_{table_prefix}_{var}_imputation
                ON {table_prefix}_{var} (imputation_m)
            """)

    print(f"  [OK] Created 9 adult_anxiety tables with indexes")


def insert_adult_anxiety_imputations(db: DatabaseManager, study_id: str, feather_dir: Path, n_imputations: int):
    """
    Insert adult_anxiety imputations from Feather files into database

    Parameters
    ----------
    db : DatabaseManager
        Database connection manager
    study_id : str
        Study identifier
    feather_dir : Path
        Directory containing Feather files
    n_imputations : int
        Number of imputations (M)
    """
    print(f"\\n[INFO] Inserting adult_anxiety imputations into database...")

    table_prefix = get_table_prefix(study_id)
    adult_anxiety_vars = [{{VARIABLE_NAMES_QUOTED_PYTHON}}]

    total_rows_inserted = 0

    for variable in adult_anxiety_vars:
        print(f"\\n[INFO] Processing {variable}...")

        # Load Feather files
        imputations = load_feather_files(feather_dir, variable, n_imputations, required=True)

        variable_rows = 0

        # Insert each imputation
        for m, df in sorted(imputations.items()):
            with db.get_connection() as conn:
                # TODO: [VALIDATION RULE] Add data type and range validation
                # Example validations:
                # - Binary: check unique values are only 0 or 1
                # - Likert 0-3: check min >= 0 and max <= 3
                # - Count: check values are non-negative integers
                #
                # if variable in ['binary_var1', 'binary_var2']:
                #     unique_vals = df[variable].unique()
                #     if not set(unique_vals).issubset({0, 1}):
                #         raise ValueError(f"Invalid binary values in {variable}: {unique_vals}")

                # Insert into table
                table_name = f"{table_prefix}_{variable}"
                df.to_sql(table_name, conn, if_exists='append', index=False)

                variable_rows += len(df)
                print(f"  [OK] Inserted {len(df)} rows for imputation m={m}")

        total_rows_inserted += variable_rows
        print(f"  [OK] Total for {variable}: {variable_rows} rows")

    print(f"\\n[OK] All adult_anxiety imputations inserted: {total_rows_inserted} total rows across 9 tables")


def update_metadata(
    db: DatabaseManager,
    study_id: str,
    variable_name: str,
    n_imputations: int,
    n_records: int,
    imputation_method: str,
    variable_type: str = "imputed"
):
    """
    Update or insert metadata for imputed/derived variable

    Parameters
    ----------
    db : DatabaseManager
        Database connection manager
    study_id : str
        Study identifier (e.g., "ne25")
    variable_name : str
        Name of variable
    n_imputations : int
        Number of imputations generated
    n_records : int
        Number of records in database
    imputation_method : str
        Method used (e.g., "cart", "rf", "derived")
    variable_type : str
        "imputed" or "derived"
    """
    with db.get_connection() as conn:
        # Check if metadata exists
        exists = conn.execute(f"""
            SELECT COUNT(*) as count
            FROM imputation_metadata
            WHERE study_id = '{study_id}' AND variable_name = '{variable_name}'
        """).df()

        notes = f"{'Derived' if variable_type == 'derived' else 'Imputed'} via adult_anxiety pipeline ({n_records} total records)"

        if exists['count'].iloc[0] > 0:
            # Update existing
            conn.execute(f"""
                UPDATE imputation_metadata
                SET n_imputations = {n_imputations},
                    imputation_method = '{imputation_method}',
                    created_date = CURRENT_TIMESTAMP,
                    created_by = '12b_insert_adult_anxiety.py',
                    notes = '{notes}'
                WHERE study_id = '{study_id}' AND variable_name = '{variable_name}'
            """)
        else:
            # Insert new
            conn.execute(f"""
                INSERT INTO imputation_metadata
                (study_id, variable_name, n_imputations, imputation_method, created_by, notes)
                VALUES (
                    '{study_id}',
                    '{variable_name}',
                    {n_imputations},
                    '{imputation_method}',
                    '12b_insert_adult_anxiety.py',
                    '{notes}'
                )
            """)


def validate_adult_anxiety_tables(db: DatabaseManager, study_id: str, n_imputations: int):
    """
    Validate adult_anxiety imputation tables

    Parameters
    ----------
    db : DatabaseManager
        Database connection manager
    study_id : str
        Study identifier
    n_imputations : int
        Expected number of imputations (M)
    """
    print(f"\\n[INFO] Validating adult_anxiety imputation tables...")

    table_prefix = get_table_prefix(study_id)
    adult_anxiety_vars = [{{VARIABLE_NAMES_QUOTED_PYTHON}}]

    with db.get_connection(read_only=True) as conn:
        for variable in adult_anxiety_vars:
            table_name = f"{table_prefix}_{variable}"

            # Check row count
            result = conn.execute(f"SELECT COUNT(*) as count FROM {table_name}").fetchone()
            total_rows = result[0]

            # Check for NULL values
            result = conn.execute(f"SELECT COUNT(*) FROM {table_name} WHERE {variable} IS NULL").fetchone()
            null_count = result[0]

            if null_count > 0:
                print(f"  [WARN] {variable}: {null_count} NULL values found")
            else:
                print(f"  [OK] {variable}: {total_rows} rows, no NULLs")

            # TODO: [VALIDATION RULE] Add domain-specific validation
            # Example patterns:
            #
            # if variable in ['binary_var1', 'binary_var2']:
            #     result = conn.execute(f"SELECT DISTINCT {variable} FROM {table_name}").fetchall()
            #     unique_vals = [row[0] for row in result]
            #     if set(unique_vals) != {0, 1}:
            #         print(f"  [WARN] {variable}: Non-binary values: {unique_vals}")
            #     else:
            #         print(f"  [OK] {variable}: Binary values (0, 1)")
            #
            # elif variable in ['likert_var1', 'likert_var2']:
            #     result = conn.execute(f"SELECT MIN({variable}), MAX({variable}) FROM {table_name}").fetchone()
            #     min_val, max_val = result[0], result[1]
            #     if min_val < 0 or max_val > 3:
            #         print(f"  [WARN] {variable}: Out of range ({min_val}-{max_val}), expected 0-3")
            #     else:
            #         print(f"  [OK] {variable}: Valid range ({min_val}-{max_val})")

    print(f"\\n[OK] Validation complete")


def main():
    """Main execution function"""
    print("=" * 60)
    print("Adult Anxiety Imputation Database Insertion")
    print("=" * 60)

    # Configuration
    study_id = "ne25"
    study_config = get_study_config(study_id)
    n_imputations = 5  # TODO: [CONFIGURATION] Get from config if needed

    # Feather directory
    feather_dir = Path(study_config['data_dir']) / "adult_anxiety_feather"

    print(f"\\nConfiguration:")
    print(f"  Study ID: {study_id}")
    print(f"  Feather directory: {feather_dir}")
    print(f"  Number of imputations: {n_imputations}")

    if not feather_dir.exists():
        raise FileNotFoundError(
            f"Feather directory not found: {feather_dir}\\n"
            f"Run adult_anxiety imputation script first: scripts/imputation/{study_id}/12_impute_adult_anxiety.R"
        )

    # Initialize database connection
    db = DatabaseManager()

    try:
        # Step 1: Create tables
        create_adult_anxiety_tables(db, study_id)

        # Step 2: Insert imputations
        insert_adult_anxiety_imputations(db, study_id, feather_dir, n_imputations)

        # Step 3: Update metadata
        adult_anxiety_vars = [{{VARIABLE_NAMES_QUOTED_PYTHON}}]
        for var in adult_anxiety_vars:
            # TODO: [CONFIGURATION] Get row count for this variable
            # This is approximate - you may want to query the actual count
            n_rows = 0  # Placeholder
            update_metadata(db, study_id, var, n_imputations, n_rows, "cart")

        # Step 4: Validate tables
        validate_adult_anxiety_tables(db, study_id, n_imputations)

        print("\\n" + "=" * 60)
        print("Adult Anxiety Imputation Database Insertion Complete!")
        print("=" * 60)

        print("\\nNext steps:")
        print("  1. Query adult_anxiety via helper functions:")
        print("     from python.imputation.helpers import get_adult_anxiety_imputations")
        print("     data = get_adult_anxiety_imputations(study_id='ne25', imputation_number=1)")
        print("  2. Update pipeline orchestrator to include Stage 12")
        print("  3. Update documentation")

    except Exception as e:
        print(f"\\n[ERROR] Database insertion failed: {e}")
        raise


if __name__ == "__main__":
    main()
```

---

## Variable Substitution Guide

When generating files, the agent should substitute these placeholders:

### Core Substitutions

| Placeholder | Example | Description |
|-------------|---------|-------------|
| `ne25` | `ne25` | Study identifier (lowercase) |
| `NE25` | `NE25` | Study identifier (uppercase) |
| `12` | `07` | Two-digit stage number |
| `adult_anxiety` | `adult_health` | Domain name (lowercase, underscores) |
| `Adult Anxiety` | `Adult Health` | Domain name (title case, spaces) |
| `cart` | `cart` | MICE imputation method |
| `9` | `9` | Number of variables to impute |
| `{{N_DERIVED}}` | `2` | Number of derived variables |
| `{{N_AUXILIARY}}` | `7` | Number of auxiliary variables |

### List Substitutions

| Placeholder | Example | Description |
|-------------|---------|-------------|
| `gad7_1, gad7_2, gad7_3, gad7_4, gad7_5, gad7_6, gad7_7, gad7_total, gad7_positive` | `phq9_1, phq9_2, ..., phq9_9` | Comma-separated variable names |
| `"gad7_1", "gad7_2", "gad7_3", "gad7_4", "gad7_5", "gad7_6", "gad7_7", "gad7_total", "gad7_positive"` | `"phq9_1", "phq9_2", "phq9_3"` | R quoted variable vector |
| `{{VARIABLE_NAMES_QUOTED_PYTHON}}` | `"phq9_1", "phq9_2", "phq9_3"` | Python quoted variable list |
| `{{EXAMPLE_VARIABLE}}` | `phq9_1` | First variable (for examples) |

### Multi-Line Substitutions

**`{{VARIABLE_DESCRIPTIONS}}`** (R comment format):
```r
#   - phq9_1 (cart) - Little interest or pleasure (0-3 scale)
#   - phq9_2 (cart) - Feeling down/depressed (0-3 scale)
#   - phq9_3 (cart) - Trouble sleeping (0-3 scale)
```

**`{{PYTHON_VARIABLE_DESCRIPTIONS}}`** (Python comment format):
```python
# - phq9_1: DOUBLE (Little interest or pleasure, 0-3 scale)
# - phq9_2: DOUBLE (Feeling down/depressed, 0-3 scale)
# - phq9_3: DOUBLE (Trouble sleeping, 0-3 scale)
```

**`{{SELECT_VARIABLES}}`** (SQL SELECT format):
```sql
      phq9_1,
      phq9_2,
      phq9_3,
      phq9_4,
```

**`
CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_1" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_1" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_1_pid_record"
    ON "ne25_imputed_gad7_1" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_1_imputation_m"
    ON "ne25_imputed_gad7_1" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_2" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_2" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_2_pid_record"
    ON "ne25_imputed_gad7_2" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_2_imputation_m"
    ON "ne25_imputed_gad7_2" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_3" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_3" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_3_pid_record"
    ON "ne25_imputed_gad7_3" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_3_imputation_m"
    ON "ne25_imputed_gad7_3" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_4" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_4" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_4_pid_record"
    ON "ne25_imputed_gad7_4" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_4_imputation_m"
    ON "ne25_imputed_gad7_4" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_5" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_5" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_5_pid_record"
    ON "ne25_imputed_gad7_5" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_5_imputation_m"
    ON "ne25_imputed_gad7_5" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_6" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_6" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_6_pid_record"
    ON "ne25_imputed_gad7_6" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_6_imputation_m"
    ON "ne25_imputed_gad7_6" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_7" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_7" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_7_pid_record"
    ON "ne25_imputed_gad7_7" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_7_imputation_m"
    ON "ne25_imputed_gad7_7" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_total" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_total" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_total_pid_record"
    ON "ne25_imputed_gad7_total" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_total_imputation_m"
    ON "ne25_imputed_gad7_total" (imputation_m);


CREATE TABLE IF NOT EXISTS "ne25_imputed_gad7_positive" (
    "study_id" VARCHAR NOT NULL,
    "pid" VARCHAR NOT NULL,
    "record_id" INTEGER NOT NULL,
    "imputation_m" INTEGER NOT NULL,
    "gad7_positive" INTEGER NOT NULL,
    PRIMARY KEY (study_id, pid, record_id, imputation_m)
);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_positive_pid_record"
    ON "ne25_imputed_gad7_positive" (pid, record_id);
CREATE INDEX IF NOT EXISTS "idx_ne25_imputed_gad7_positive_imputation_m"
    ON "ne25_imputed_gad7_positive" (imputation_m);
`** (SQL DDL format):
```python
        # phq9_1 (DOUBLE - 0-3 Likert scale)
        # TODO: [DATA TYPE] Verify DOUBLE is appropriate for phq9_1
        conn.execute(f"""
            DROP TABLE IF EXISTS {table_prefix}_phq9_1
        """)
        conn.execute(f"""
            CREATE TABLE {table_prefix}_phq9_1 (
                study_id VARCHAR NOT NULL,
                pid INTEGER NOT NULL,
                record_id INTEGER NOT NULL,
                imputation_m INTEGER NOT NULL,
                phq9_1 DOUBLE NOT NULL,
                PRIMARY KEY (study_id, pid, record_id, imputation_m)
            )
        """)
```

### Data Type Mapping

Map user-specified data types to SQL types:

| User Input | SQL Type | Use Case |
|------------|----------|----------|
| `"0-3 likert"`, `"0-4 likert"` | `DOUBLE` | Ordinal scales |
| `"continuous"`, `"numeric"` | `DOUBLE` | Continuous variables |
| `"binary"`, `"0/1"` | `INTEGER` | Binary indicators |
| `"count"`, `"integer"` | `INTEGER` | Count variables |
| `"boolean"`, `"true/false"` | `BOOLEAN` | Boolean flags |
| `"categorical"`, `"factor"` | `VARCHAR` | Categorical (rare) |

---

## TODO Marker Examples

### Example 1: Predictor Matrix Configuration

```r
# TODO: [DOMAIN LOGIC] Configure predictor matrix
#
# Decision points:
# 1. Which auxiliary variables should predict phq9_1?
#    Available: puma (geography), raceG, income, educ_a1 (sociodem),
#               age_in_days, female (demographics), authentic.x (quality)
#
# 2. Should PHQ-9 items predict each other?
#    - Pros: Items are related (depression construct), may improve imputation
#    - Cons: Could introduce circularity if relationships are too strong
#    - Common practice: Include for mental health scales
#
# 3. Review correlation matrix:
#    Run this before finalizing: cor(dat_m[, c(imp_vars, aux_vars)], use="pairwise.complete.obs")
#
# Resources:
# - Similar implementation: scripts/imputation/ne25/05_impute_adult_mental_health.R (lines 524-545)
# - Theory: PHQ-9 items typically correlate 0.5-0.7 with each other
#
for (var in imp_vars) {
  predictor_matrix[var, aux_vars_existing] <- 1  # Use auxiliary variables
  predictor_matrix[var, setdiff(imp_vars, var)] <- 1  # TODO: Use other PHQ-9 items?
}
```

### Example 2: MICE Method Selection

```r
# TODO: [STATISTICAL DECISION] Verify MICE method is appropriate
#
# Current method: cart (classification and regression trees)
#
# Considerations for PHQ-9 items (0-3 ordinal):
# 1. Variable type: Ordinal (0-3 scale)
#    - cart: ✅ Handles ordinal data well
#    - rf: ✅ Also good, but slower
#    - pmm: ✅ Preserves distribution
#    - polr: Could use for ordinal, but more assumptions
#
# 2. Sample size: N = {{N}} after filtering
#    - cart: ✅ Works with moderate N
#    - rf: Needs larger N (rule of thumb: 10*p obs per tree)
#
# 3. Assumptions:
#    - cart: ✅ No distributional assumptions
#    - Handles non-linearity and interactions automatically
#
# 4. Computational cost:
#    - cart: Fast (good for 9 variables × 5 imputations)
#    - rf: Slower but may not add much for simple scales
#
# Recommendation: cart is appropriate for PHQ-9 given ordinal nature
# and moderate sample size. Consider rf if N > 1000 and you suspect
# complex interactions.
#
method_vector[var] <- "cart"  # TODO: Confirm based on analysis
```

### Example 3: Validation Rule

```python
# TODO: [VALIDATION RULE] Add value range validation for phq9_total
#
# Expected properties:
# - Range: 0-27 (sum of 9 items, each 0-3)
# - Distribution: Right-skewed (most people low scores)
# - Missing: Should be imputed for any record where ANY PHQ-9 item was missing
#
# Common issues to check:
# - Values > 27: Summation error
# - Values < 0: Invalid imputation
# - All values = 0: Imputation failed
# - Strange distribution: Check for systematically wrong imputations
#
# Example validation:
if variable == "phq9_total":
    # Check range
    result = conn.execute(f"SELECT MIN({variable}), MAX({variable}) FROM {table_name}").fetchone()
    min_val, max_val = result[0], result[1]
    if min_val < 0 or max_val > 27:
        print(f"  [ERROR] {variable}: Invalid range ({min_val}-{max_val}), expected 0-27")
    else:
        print(f"  [OK] {variable}: Valid range ({min_val}-{max_val})")

    # Check distribution
    result = conn.execute(f"SELECT AVG({variable}), STDDEV({variable}) FROM {table_name}").fetchone()
    mean_val, std_val = result[0], result[1]
    print(f"  [INFO] {variable}: mean={mean_val:.2f}, sd={std_val:.2f}")
    if mean_val > 15:  # Unusually high for general population
        print(f"  [WARN] {variable}: Mean is unusually high - check imputation")
```

---

**For usage, see:** `docs/imputation/ADDING_IMPUTATION_STAGES.md`

*Last Updated: October 2025 | Version: 1.0.0*
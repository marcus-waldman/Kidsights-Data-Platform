"""
Insert Childcare Imputations into DuckDB

Reads Feather files generated by childcare imputation scripts (03a, 03b, 03c)
and inserts imputed/derived values into DuckDB tables.

This script handles 4 childcare variables:
- cc_receives_care: Boolean (Stage 1 imputation)
- cc_primary_type: Categorical (Stage 2 conditional imputation)
- cc_hours_per_week: Continuous (Stage 2 conditional imputation)
- childcare_10hrs_nonfamily: Boolean (Stage 3 derived)

Usage:
    python scripts/imputation/ne25/04_insert_childcare_imputations.py
"""

import sys
from pathlib import Path
import pandas as pd

# Add project root to path
project_root = Path(__file__).resolve().parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from python.db.connection import DatabaseManager
from python.imputation.config import get_study_config, get_table_prefix


def load_feather_files(feather_dir: Path, variable_name: str, n_imputations: int, required: bool = True):
    """
    Load Feather files for a single variable across all imputations

    Parameters
    ----------
    feather_dir : Path
        Directory containing Feather files
    variable_name : str
        Name of variable (e.g., "cc_receives_care", "cc_primary_type")
    n_imputations : int
        Number of imputations to load (M)
    required : bool
        If True, raise error if files not found. If False, return empty dict.

    Returns
    -------
    dict
        Dictionary mapping imputation_m to DataFrame
    """
    # Pattern: {variable}_m{m}.feather (e.g., cc_receives_care_m1.feather)
    pattern = f"{variable_name}_m*.feather"
    feather_files = sorted(feather_dir.glob(pattern))

    if len(feather_files) == 0:
        if required:
            raise FileNotFoundError(
                f"No Feather files found for variable '{variable_name}' in {feather_dir}\n"
                f"Expected pattern: {pattern}\n"
                f"Run childcare imputation scripts first"
            )
        else:
            print(f"  [WARN] No Feather files found for {variable_name} (may not be needed)")
            return {}

    imputations = {}

    for f in feather_files:
        # Extract m from filename (e.g., cc_receives_care_m1.feather -> 1)
        import re
        match = re.search(r'_m(\d+)$', f.stem)
        if not match:
            raise ValueError(f"Could not extract imputation number from filename: {f.name}")
        m = int(match.group(1))
        df = pd.read_feather(f)

        # Validate columns
        expected_cols = {'study_id', 'pid', 'record_id', 'imputation_m', variable_name}
        if not expected_cols.issubset(df.columns):
            raise ValueError(
                f"Missing columns in {f.name}. Expected: {expected_cols}, Got: {set(df.columns)}"
            )

        imputations[m] = df

    if len(imputations) != n_imputations:
        print(f"  [WARN] Expected {n_imputations} files, found {len(imputations)} for {variable_name}")

    return imputations


def create_childcare_tables(db: DatabaseManager, study_id: str):
    """
    Create database tables for childcare imputations

    Following sociodemographic pattern: separate table per variable with naming:
    {study_id}_imputed_{variable_name}

    Parameters
    ----------
    db : DatabaseManager
        Database connection manager
    study_id : str
        Study identifier (e.g., "ne25")
    """
    print(f"\n[INFO] Creating childcare imputation tables...")

    table_prefix = get_table_prefix(study_id)

    with db.get_connection() as conn:
        # Table 1: ne25_imputed_cc_receives_care (BOOLEAN)
        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_prefix}_cc_receives_care (
                study_id VARCHAR NOT NULL,
                pid INTEGER NOT NULL,
                record_id INTEGER NOT NULL,
                imputation_m INTEGER NOT NULL,
                cc_receives_care BOOLEAN NOT NULL,
                PRIMARY KEY (study_id, pid, record_id, imputation_m)
            )
        """)

        # Table 2: ne25_imputed_cc_primary_type (VARCHAR)
        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_prefix}_cc_primary_type (
                study_id VARCHAR NOT NULL,
                pid INTEGER NOT NULL,
                record_id INTEGER NOT NULL,
                imputation_m INTEGER NOT NULL,
                cc_primary_type VARCHAR NOT NULL,
                PRIMARY KEY (study_id, pid, record_id, imputation_m)
            )
        """)

        # Table 3: ne25_imputed_cc_hours_per_week (DOUBLE)
        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_prefix}_cc_hours_per_week (
                study_id VARCHAR NOT NULL,
                pid INTEGER NOT NULL,
                record_id INTEGER NOT NULL,
                imputation_m INTEGER NOT NULL,
                cc_hours_per_week DOUBLE NOT NULL,
                PRIMARY KEY (study_id, pid, record_id, imputation_m)
            )
        """)

        # Table 4: ne25_imputed_childcare_10hrs_nonfamily (BOOLEAN) - DERIVED
        # NOTE: Allows NULL because derivation requires completed values from Stages 1 & 2
        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_prefix}_childcare_10hrs_nonfamily (
                study_id VARCHAR NOT NULL,
                pid INTEGER NOT NULL,
                record_id INTEGER NOT NULL,
                imputation_m INTEGER NOT NULL,
                childcare_10hrs_nonfamily BOOLEAN,  -- NULL allowed for incomplete upstream imputations
                PRIMARY KEY (study_id, pid, record_id, imputation_m)
            )
        """)

    print(f"  [OK] Created 4 childcare tables")


def insert_variable_imputations(
    db: DatabaseManager,
    variable_name: str,
    imputations_dict: dict,
    study_id: str = "ne25",
    variable_type: str = "imputed"
):
    """
    Insert imputations for a single variable into database

    Parameters
    ----------
    db : DatabaseManager
        Database connection manager
    variable_name : str
        Name of variable (e.g., "cc_receives_care", "cc_primary_type")
    imputations_dict : dict
        Dictionary mapping imputation_m to DataFrame
    study_id : str
        Study identifier
    variable_type : str
        "imputed" or "derived"

    Returns
    -------
    int
        Number of rows inserted
    """
    if len(imputations_dict) == 0:
        print(f"  [SKIP] No data found for {variable_name}")
        return 0

    print(f"\n[INFO] Inserting {variable_name} {variable_type} values...")

    table_prefix = get_table_prefix(study_id)
    table_name = f"{table_prefix}_{variable_name}"

    # Combine all imputations for this variable
    all_imputations = []

    for m, df in imputations_dict.items():
        if len(df) == 0:
            print(f"  [WARN] No {variable_type} values for {variable_name} in m={m}")
            continue

        # Validate expected columns
        if variable_name not in df.columns:
            raise ValueError(f"Column '{variable_name}' not found in imputation m={m}")

        # Select only needed columns
        var_df = df[['study_id', 'pid', 'record_id', 'imputation_m', variable_name]].copy()

        all_imputations.append(var_df)

    if len(all_imputations) == 0:
        print(f"  [SKIP] No {variable_type} values found for {variable_name}")
        return 0

    # Combine all imputations
    combined_df = pd.concat(all_imputations, ignore_index=True)

    print(f"  Combined {len(combined_df)} rows across {len(imputations_dict)} imputations")

    # Insert into database
    with db.get_connection() as conn:
        # Clear existing imputations for this study
        conn.execute(f"""
            DELETE FROM {table_name}
            WHERE study_id = '{study_id}'
        """)

        # Insert new imputations
        conn.execute(f"""
            INSERT INTO {table_name}
            SELECT * FROM combined_df
        """)

    print(f"  [OK] Inserted {len(combined_df)} rows into {table_name}")

    return len(combined_df)


def update_metadata(
    db: DatabaseManager,
    study_id: str,
    variable_name: str,
    n_imputations: int,
    n_records: int,
    imputation_method: str,
    variable_type: str = "imputed"
):
    """
    Update or insert metadata for imputed/derived variable

    Parameters
    ----------
    db : DatabaseManager
        Database connection manager
    study_id : str
        Study identifier (e.g., "ne25")
    variable_name : str
        Name of variable
    n_imputations : int
        Number of imputations generated
    n_records : int
        Number of records in database
    imputation_method : str
        Method used (e.g., "cart", "derived")
    variable_type : str
        "imputed" or "derived"
    """
    with db.get_connection() as conn:
        # Check if metadata exists
        exists = conn.execute(f"""
            SELECT COUNT(*) as count
            FROM imputation_metadata
            WHERE study_id = '{study_id}' AND variable_name = '{variable_name}'
        """).df()

        notes = f"{'Derived' if variable_type == 'derived' else 'Imputed'} via childcare pipeline ({n_records} total records)"

        if exists['count'].iloc[0] > 0:
            # Update existing
            conn.execute(f"""
                UPDATE imputation_metadata
                SET n_imputations = {n_imputations},
                    imputation_method = '{imputation_method}',
                    created_date = CURRENT_TIMESTAMP,
                    created_by = '04_insert_childcare_imputations.py',
                    notes = '{notes}'
                WHERE study_id = '{study_id}' AND variable_name = '{variable_name}'
            """)
        else:
            # Insert new
            conn.execute(f"""
                INSERT INTO imputation_metadata
                (study_id, variable_name, n_imputations, imputation_method, created_by, notes)
                VALUES (
                    '{study_id}',
                    '{variable_name}',
                    {n_imputations},
                    '{imputation_method}',
                    '04_insert_childcare_imputations.py',
                    '{notes}'
                )
            """)


def validate_insertions(db: DatabaseManager, study_id: str, n_imputations: int):
    """
    Validate that all childcare tables have expected data

    Parameters
    ----------
    db : DatabaseManager
        Database connection manager
    study_id : str
        Study identifier
    n_imputations : int
        Expected number of imputations (M)
    """
    print(f"\n[INFO] Validating insertions...")

    table_prefix = get_table_prefix(study_id)
    childcare_vars = [
        'cc_receives_care',
        'cc_primary_type',
        'cc_hours_per_week',
        'childcare_10hrs_nonfamily'
    ]

    with db.get_connection() as conn:
        for var in childcare_vars:
            table_name = f"{table_prefix}_{var}"

            # Check row count
            result = conn.execute(f"""
                SELECT COUNT(*) as count
                FROM {table_name}
                WHERE study_id = '{study_id}'
            """).df()

            count = result['count'].iloc[0]
            print(f"  {var}: {count} rows")

            # Check imputation_m coverage
            result = conn.execute(f"""
                SELECT DISTINCT imputation_m
                FROM {table_name}
                WHERE study_id = '{study_id}'
                ORDER BY imputation_m
            """).df()

            m_values = result['imputation_m'].tolist()
            if len(m_values) != n_imputations:
                print(f"    [WARN] Expected {n_imputations} imputations, found {len(m_values)}")

            # Check for duplicates
            result = conn.execute(f"""
                SELECT pid, record_id, imputation_m, COUNT(*) as dup_count
                FROM {table_name}
                WHERE study_id = '{study_id}'
                GROUP BY pid, record_id, imputation_m
                HAVING COUNT(*) > 1
            """).df()

            if len(result) > 0:
                print(f"    [ERROR] Found {len(result)} duplicate records!")
            else:
                print(f"    [OK] No duplicates")

    print(f"\n[OK] Validation complete")


def main():
    """
    Main insertion workflow
    """
    print("Insert Childcare Imputations into DuckDB")
    print("=" * 60)

    # Load study-specific configuration
    study_id = "ne25"
    config = get_study_config(study_id)

    print(f"Configuration:")
    print(f"  Study: {config['study_name']}")
    print(f"  Study ID: {study_id}")
    print(f"  Number of imputations (M): {config['n_imputations']}")
    print(f"  Database: {config['database']['db_path']}")

    # Connect to database
    db = DatabaseManager()
    print(f"\n[OK] Connected to database")

    # Create tables
    create_childcare_tables(db, study_id)

    # Feather files directory (study-specific)
    feather_dir = project_root / config['data_dir'] / "childcare_feather"
    print(f"\n[INFO] Loading Feather files from: {feather_dir}")

    # Define childcare variables
    # Stage 1 (always present)
    stage1_vars = ["cc_receives_care"]
    # Stage 2 (conditional - may have fewer records)
    stage2_vars = ["cc_primary_type", "cc_hours_per_week"]
    # Stage 3 (derived - always present for all eligible)
    stage3_vars = ["childcare_10hrs_nonfamily"]

    n_imputations = config['n_imputations']

    # Process Stage 1: cc_receives_care (required)
    print(f"\n{'='*60}")
    print("STAGE 1: cc_receives_care (Boolean Imputation)")
    print(f"{'='*60}")

    for var in stage1_vars:
        imputations = load_feather_files(feather_dir, var, n_imputations, required=True)
        n_rows = insert_variable_imputations(db, var, imputations, study_id, variable_type="imputed")
        update_metadata(db, study_id, var, n_imputations, n_rows, "cart", variable_type="imputed")

    # Process Stage 2: cc_primary_type, cc_hours_per_week (conditional)
    print(f"\n{'='*60}")
    print("STAGE 2: Conditional Imputation (Type + Hours)")
    print(f"{'='*60}")

    for var in stage2_vars:
        imputations = load_feather_files(feather_dir, var, n_imputations, required=False)
        n_rows = insert_variable_imputations(db, var, imputations, study_id, variable_type="imputed")
        if n_rows > 0:
            update_metadata(db, study_id, var, n_imputations, n_rows, "cart", variable_type="imputed")

    # Process Stage 3: childcare_10hrs_nonfamily (derived)
    print(f"\n{'='*60}")
    print("STAGE 3: Derived Outcome (childcare_10hrs_nonfamily)")
    print(f"{'='*60}")

    for var in stage3_vars:
        imputations = load_feather_files(feather_dir, var, n_imputations, required=True)
        n_rows = insert_variable_imputations(db, var, imputations, study_id, variable_type="derived")
        update_metadata(db, study_id, var, n_imputations, n_rows, "derived", variable_type="derived")

    # Validate
    validate_insertions(db, study_id, n_imputations)

    print(f"\n{'='*60}")
    print("INSERTION COMPLETE")
    print(f"{'='*60}")
    print(f"\n[OK] Successfully inserted all childcare imputations")
    print(f"  - 4 variables: cc_receives_care, cc_primary_type, cc_hours_per_week, childcare_10hrs_nonfamily")
    print(f"  - {n_imputations} imputations per variable")
    print(f"  - Database: {config['database']['db_path']}")


if __name__ == "__main__":
    main()

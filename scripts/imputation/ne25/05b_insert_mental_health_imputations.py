"""
Insert Adult Mental Health & Parenting Imputations into DuckDB

Reads Feather files generated by mental health imputation script (05_impute_adult_mental_health.R)
and inserts imputed/derived values into DuckDB tables.

This script handles 7 mental health & parenting variables:
- phq2_interest: Numeric 0-3 (PHQ-2 item 1 - little interest/pleasure)
- phq2_depressed: Numeric 0-3 (PHQ-2 item 2 - feeling down/depressed)
- gad2_nervous: Numeric 0-3 (GAD-2 item 1 - feeling nervous/anxious)
- gad2_worry: Numeric 0-3 (GAD-2 item 2 - unable to stop worrying)
- q1502: Numeric 0-3 (parenting self-efficacy - handling day-to-day demands)
- phq2_positive: Boolean (derived - PHQ-2 positive screen >= 3)
- gad2_positive: Boolean (derived - GAD-2 positive screen >= 3)

Usage:
    python scripts/imputation/ne25/05b_insert_mental_health_imputations.py
"""

import sys
from pathlib import Path
import pandas as pd

# Add project root to path
project_root = Path(__file__).resolve().parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from python.db.connection import DatabaseManager
from python.imputation.config import get_study_config, get_table_prefix


def load_feather_files(feather_dir: Path, variable_name: str, n_imputations: int, required: bool = True):
    """
    Load Feather files for a single variable across all imputations

    Parameters
    ----------
    feather_dir : Path
        Directory containing Feather files
    variable_name : str
        Name of variable (e.g., "phq2_interest", "phq2_positive")
    n_imputations : int
        Number of imputations to load (M)
    required : bool
        If True, raise error if files not found. If False, return empty dict.

    Returns
    -------
    dict
        Dictionary mapping imputation_m to DataFrame
    """
    # Pattern: {variable}_m{m}.feather (e.g., phq2_interest_m1.feather)
    pattern = f"{variable_name}_m*.feather"
    feather_files = sorted(feather_dir.glob(pattern))

    if len(feather_files) == 0:
        if required:
            raise FileNotFoundError(
                f"No Feather files found for variable '{variable_name}' in {feather_dir}\n"
                f"Expected pattern: {pattern}\n"
                f"Run mental health imputation script first: scripts/imputation/ne25/05_impute_adult_mental_health.R"
            )
        else:
            print(f"  [WARN] No Feather files found for {variable_name}")
            return {}

    imputations = {}

    for f in feather_files:
        # Extract m from filename (e.g., phq2_interest_m1.feather -> 1)
        import re
        match = re.search(r'_m(\d+)$', f.stem)
        if not match:
            raise ValueError(f"Could not extract imputation number from filename: {f.name}")
        m = int(match.group(1))
        df = pd.read_feather(f)

        # Validate columns
        expected_cols = {'study_id', 'pid', 'record_id', 'imputation_m', variable_name}
        if not expected_cols.issubset(df.columns):
            raise ValueError(
                f"Missing columns in {f.name}. Expected: {expected_cols}, Got: {set(df.columns)}"
            )

        imputations[m] = df

    if len(imputations) != n_imputations:
        print(f"  [WARN] Expected {n_imputations} files, found {len(imputations)} for {variable_name}")

    return imputations


def create_mental_health_tables(db: DatabaseManager, study_id: str):
    """
    Create database tables for mental health & parenting imputations

    Following pattern: separate table per variable with naming:
    {study_id}_imputed_{variable_name}

    Parameters
    ----------
    db : DatabaseManager
        Database connection manager
    study_id : str
        Study identifier (e.g., "ne25")
    """
    print(f"\n[INFO] Creating mental health & parenting imputation tables...")

    table_prefix = get_table_prefix(study_id)

    with db.get_connection() as conn:
        # PHQ-2 Items (0-3 scale, DOUBLE for numeric storage)
        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_prefix}_phq2_interest (
                study_id VARCHAR NOT NULL,
                pid INTEGER NOT NULL,
                record_id INTEGER NOT NULL,
                imputation_m INTEGER NOT NULL,
                phq2_interest DOUBLE NOT NULL,
                PRIMARY KEY (study_id, pid, record_id, imputation_m)
            )
        """)

        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_prefix}_phq2_depressed (
                study_id VARCHAR NOT NULL,
                pid INTEGER NOT NULL,
                record_id INTEGER NOT NULL,
                imputation_m INTEGER NOT NULL,
                phq2_depressed DOUBLE NOT NULL,
                PRIMARY KEY (study_id, pid, record_id, imputation_m)
            )
        """)

        # GAD-2 Items (0-3 scale, DOUBLE for numeric storage)
        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_prefix}_gad2_nervous (
                study_id VARCHAR NOT NULL,
                pid INTEGER NOT NULL,
                record_id INTEGER NOT NULL,
                imputation_m INTEGER NOT NULL,
                gad2_nervous DOUBLE NOT NULL,
                PRIMARY KEY (study_id, pid, record_id, imputation_m)
            )
        """)

        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_prefix}_gad2_worry (
                study_id VARCHAR NOT NULL,
                pid INTEGER NOT NULL,
                record_id INTEGER NOT NULL,
                imputation_m INTEGER NOT NULL,
                gad2_worry DOUBLE NOT NULL,
                PRIMARY KEY (study_id, pid, record_id, imputation_m)
            )
        """)

        # Parenting Self-Efficacy (0-3 scale, DOUBLE for numeric storage)
        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_prefix}_q1502 (
                study_id VARCHAR NOT NULL,
                pid INTEGER NOT NULL,
                record_id INTEGER NOT NULL,
                imputation_m INTEGER NOT NULL,
                q1502 DOUBLE NOT NULL,
                PRIMARY KEY (study_id, pid, record_id, imputation_m)
            )
        """)

        # Derived Positive Screens (BOOLEAN)
        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_prefix}_phq2_positive (
                study_id VARCHAR NOT NULL,
                pid INTEGER NOT NULL,
                record_id INTEGER NOT NULL,
                imputation_m INTEGER NOT NULL,
                phq2_positive BOOLEAN NOT NULL,
                PRIMARY KEY (study_id, pid, record_id, imputation_m)
            )
        """)

        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {table_prefix}_gad2_positive (
                study_id VARCHAR NOT NULL,
                pid INTEGER NOT NULL,
                record_id INTEGER NOT NULL,
                imputation_m INTEGER NOT NULL,
                gad2_positive BOOLEAN NOT NULL,
                PRIMARY KEY (study_id, pid, record_id, imputation_m)
            )
        """)

    print(f"  [OK] Created 7 mental health & parenting tables")


def insert_variable_imputations(
    db: DatabaseManager,
    variable_name: str,
    imputations_dict: dict,
    study_id: str = "ne25",
    variable_type: str = "imputed"
):
    """
    Insert imputations for a single variable into database

    Parameters
    ----------
    db : DatabaseManager
        Database connection manager
    variable_name : str
        Name of variable (e.g., "phq2_interest", "phq2_positive")
    imputations_dict : dict
        Dictionary mapping imputation_m to DataFrame
    study_id : str
        Study identifier
    variable_type : str
        "imputed" or "derived"

    Returns
    -------
    int
        Number of rows inserted
    """
    if len(imputations_dict) == 0:
        print(f"  [SKIP] No data found for {variable_name}")
        return 0

    print(f"\n[INFO] Inserting {variable_name} {variable_type} values...")

    table_prefix = get_table_prefix(study_id)
    table_name = f"{table_prefix}_{variable_name}"

    # Combine all imputations for this variable
    all_imputations = []

    for m, df in imputations_dict.items():
        if len(df) == 0:
            print(f"  [WARN] No {variable_type} values for {variable_name} in m={m}")
            continue

        # Validate expected columns
        if variable_name not in df.columns:
            raise ValueError(f"Column '{variable_name}' not found in imputation m={m}")

        # Select only needed columns
        var_df = df[['study_id', 'pid', 'record_id', 'imputation_m', variable_name]].copy()

        # DEFENSIVE NULL FILTERING (CRITICAL)
        # Remove rows where imputed value is NULL to prevent database constraint violations
        null_mask = var_df[variable_name].isna()
        n_nulls = null_mask.sum()

        if n_nulls > 0:
            print(f"  [WARN] Filtering {n_nulls} NULL values from {variable_name} m={m}")
            var_df = var_df[~null_mask].copy()

        all_imputations.append(var_df)

    if len(all_imputations) == 0:
        print(f"  [SKIP] No {variable_type} values found for {variable_name}")
        return 0

    # Combine all imputations
    combined_df = pd.concat(all_imputations, ignore_index=True)

    print(f"  Combined {len(combined_df)} rows across {len(imputations_dict)} imputations")

    # Insert into database
    with db.get_connection() as conn:
        # Clear existing imputations for this study
        conn.execute(f"""
            DELETE FROM {table_name}
            WHERE study_id = '{study_id}'
        """)

        # Insert new imputations
        conn.execute(f"""
            INSERT INTO {table_name}
            SELECT * FROM combined_df
        """)

    print(f"  [OK] Inserted {len(combined_df)} rows into {table_name}")

    return len(combined_df)


def update_metadata(
    db: DatabaseManager,
    study_id: str,
    variable_name: str,
    n_imputations: int,
    n_records: int,
    imputation_method: str,
    variable_type: str = "imputed"
):
    """
    Update or insert metadata for imputed/derived variable

    Parameters
    ----------
    db : DatabaseManager
        Database connection manager
    study_id : str
        Study identifier (e.g., "ne25")
    variable_name : str
        Name of variable
    n_imputations : int
        Number of imputations generated
    n_records : int
        Number of records in database
    imputation_method : str
        Method used (e.g., "cart", "derived")
    variable_type : str
        "imputed" or "derived"
    """
    with db.get_connection() as conn:
        # Check if metadata exists
        exists = conn.execute(f"""
            SELECT COUNT(*) as count
            FROM imputation_metadata
            WHERE study_id = '{study_id}' AND variable_name = '{variable_name}'
        """).df()

        notes = f"{'Derived' if variable_type == 'derived' else 'Imputed'} via mental health pipeline ({n_records} total records)"

        if exists['count'].iloc[0] > 0:
            # Update existing
            conn.execute(f"""
                UPDATE imputation_metadata
                SET n_imputations = {n_imputations},
                    imputation_method = '{imputation_method}',
                    created_date = CURRENT_TIMESTAMP,
                    created_by = '05b_insert_mental_health_imputations.py',
                    notes = '{notes}'
                WHERE study_id = '{study_id}' AND variable_name = '{variable_name}'
            """)
        else:
            # Insert new
            conn.execute(f"""
                INSERT INTO imputation_metadata
                (study_id, variable_name, n_imputations, imputation_method, created_by, notes)
                VALUES (
                    '{study_id}',
                    '{variable_name}',
                    {n_imputations},
                    '{imputation_method}',
                    '05b_insert_mental_health_imputations.py',
                    '{notes}'
                )
            """)


def validate_insertions(db: DatabaseManager, study_id: str, n_imputations: int):
    """
    Validate that all mental health tables have expected data

    Parameters
    ----------
    db : DatabaseManager
        Database connection manager
    study_id : str
        Study identifier
    n_imputations : int
        Expected number of imputations (M)
    """
    print(f"\n[INFO] Validating insertions...")

    table_prefix = get_table_prefix(study_id)
    mental_health_vars = [
        'phq2_interest',
        'phq2_depressed',
        'gad2_nervous',
        'gad2_worry',
        'q1502',
        'phq2_positive',
        'gad2_positive'
    ]

    validation_results = {}

    with db.get_connection() as conn:
        for var in mental_health_vars:
            table_name = f"{table_prefix}_{var}"

            # Check row count
            result = conn.execute(f"""
                SELECT COUNT(*) as count
                FROM {table_name}
                WHERE study_id = '{study_id}'
            """).df()

            count = result['count'].iloc[0]
            print(f"  {var}: {count} rows")
            validation_results[var] = count

            # Check imputation_m coverage
            result = conn.execute(f"""
                SELECT DISTINCT imputation_m
                FROM {table_name}
                WHERE study_id = '{study_id}'
                ORDER BY imputation_m
            """).df()

            m_values = result['imputation_m'].tolist()
            if len(m_values) != n_imputations:
                print(f"    [WARN] Expected {n_imputations} imputations, found {len(m_values)}")

            # Check for duplicates
            result = conn.execute(f"""
                SELECT pid, record_id, imputation_m, COUNT(*) as dup_count
                FROM {table_name}
                WHERE study_id = '{study_id}'
                GROUP BY pid, record_id, imputation_m
                HAVING COUNT(*) > 1
            """).df()

            if len(result) > 0:
                print(f"    [ERROR] Found {len(result)} duplicate records!")
            else:
                print(f"    [OK] No duplicates")

            # Value range validation (items should be 0-3, positives should be boolean)
            if var in ['phq2_interest', 'phq2_depressed', 'gad2_nervous', 'gad2_worry', 'q1502']:
                result = conn.execute(f"""
                    SELECT MIN({var}) as min_val, MAX({var}) as max_val
                    FROM {table_name}
                    WHERE study_id = '{study_id}'
                """).df()

                min_val = result['min_val'].iloc[0]
                max_val = result['max_val'].iloc[0]

                if min_val < 0 or max_val > 3:
                    print(f"    [ERROR] Values out of range 0-3: min={min_val}, max={max_val}")
                else:
                    print(f"    [OK] Values in range 0-3")

    print(f"\n[OK] Validation complete")

    return validation_results


def calculate_prevalence_statistics(db: DatabaseManager, study_id: str, n_imputations: int):
    """
    Calculate and report prevalence statistics for positive screens

    Parameters
    ----------
    db : DatabaseManager
        Database connection manager
    study_id : str
        Study identifier
    n_imputations : int
        Number of imputations
    """
    print(f"\n[INFO] Calculating prevalence statistics...")

    table_prefix = get_table_prefix(study_id)

    with db.get_connection() as conn:
        # PHQ-2+ prevalence across imputations
        print(f"\n  PHQ-2 Positive Screen Prevalence:")
        for m in range(1, n_imputations + 1):
            result = conn.execute(f"""
                SELECT
                    COUNT(*) as total,
                    SUM(CASE WHEN phq2_positive THEN 1 ELSE 0 END) as positive
                FROM {table_prefix}_phq2_positive
                WHERE study_id = '{study_id}' AND imputation_m = {m}
            """).df()

            total = result['total'].iloc[0]
            positive = result['positive'].iloc[0]
            pct = 100 * positive / total if total > 0 else 0
            print(f"    m={m}: {positive}/{total} ({pct:.1f}%)")

        # GAD-2+ prevalence across imputations
        print(f"\n  GAD-2 Positive Screen Prevalence:")
        for m in range(1, n_imputations + 1):
            result = conn.execute(f"""
                SELECT
                    COUNT(*) as total,
                    SUM(CASE WHEN gad2_positive THEN 1 ELSE 0 END) as positive
                FROM {table_prefix}_gad2_positive
                WHERE study_id = '{study_id}' AND imputation_m = {m}
            """).df()

            total = result['total'].iloc[0]
            positive = result['positive'].iloc[0]
            pct = 100 * positive / total if total > 0 else 0
            print(f"    m={m}: {positive}/{total} ({pct:.1f}%)")

        # q1502 mean across imputations
        print(f"\n  Parenting Self-Efficacy (q1502) Mean:")
        for m in range(1, n_imputations + 1):
            result = conn.execute(f"""
                SELECT AVG(q1502) as mean_q1502
                FROM {table_prefix}_q1502
                WHERE study_id = '{study_id}' AND imputation_m = {m}
            """).df()

            mean_val = result['mean_q1502'].iloc[0]
            print(f"    m={m}: {mean_val:.2f}")


def main():
    """
    Main insertion workflow
    """
    print("Insert Adult Mental Health & Parenting Imputations into DuckDB")
    print("=" * 60)

    # Load study-specific configuration
    study_id = "ne25"
    config = get_study_config(study_id)

    print(f"Configuration:")
    print(f"  Study: {config['study_name']}")
    print(f"  Study ID: {study_id}")
    print(f"  Number of imputations (M): {config['n_imputations']}")
    print(f"  Database: {config['database']['db_path']}")

    # Connect to database
    db = DatabaseManager()
    print(f"\n[OK] Connected to database")

    # Create tables
    create_mental_health_tables(db, study_id)

    # Feather files directory (study-specific)
    feather_dir = project_root / config['data_dir'] / "mental_health_feather"
    print(f"\n[INFO] Loading Feather files from: {feather_dir}")

    # Define mental health variables
    # PHQ-2/GAD-2 items + parenting (imputed)
    imputed_vars = ["phq2_interest", "phq2_depressed", "gad2_nervous", "gad2_worry", "q1502"]
    # Positive screens (derived)
    derived_vars = ["phq2_positive", "gad2_positive"]

    n_imputations = config['n_imputations']

    # Process imputed variables (5 items)
    print(f"\n{'='*60}")
    print("MENTAL HEALTH ITEMS: PHQ-2, GAD-2, Parenting (CART Imputation)")
    print(f"{'='*60}")

    for var in imputed_vars:
        imputations = load_feather_files(feather_dir, var, n_imputations, required=True)
        n_rows = insert_variable_imputations(db, var, imputations, study_id, variable_type="imputed")
        update_metadata(db, study_id, var, n_imputations, n_rows, "cart", variable_type="imputed")

    # Process derived variables (2 positive screens)
    print(f"\n{'='*60}")
    print("DERIVED VARIABLES: PHQ-2+ and GAD-2+ Positive Screens")
    print(f"{'='*60}")

    for var in derived_vars:
        imputations = load_feather_files(feather_dir, var, n_imputations, required=True)
        n_rows = insert_variable_imputations(db, var, imputations, study_id, variable_type="derived")
        update_metadata(db, study_id, var, n_imputations, n_rows, "derived", variable_type="derived")

    # Validate
    validation_results = validate_insertions(db, study_id, n_imputations)

    # Calculate prevalence statistics
    calculate_prevalence_statistics(db, study_id, n_imputations)

    print(f"\n{'='*60}")
    print("INSERTION COMPLETE")
    print(f"{'='*60}")
    print(f"\n[OK] Successfully inserted all mental health & parenting imputations")
    print(f"  - 7 variables: phq2_interest, phq2_depressed, gad2_nervous, gad2_worry, q1502, phq2_positive, gad2_positive")
    print(f"  - {n_imputations} imputations per variable")
    print(f"  - Database: {config['database']['db_path']}")

    # Summary by variable type
    print(f"\nDatabase Summary:")
    print(f"  Imputed items (5): {sum(validation_results[v] for v in imputed_vars)} total rows")
    print(f"  Derived screens (2): {sum(validation_results[v] for v in derived_vars)} total rows")
    print(f"  Grand total: {sum(validation_results.values())} rows across 7 tables")


if __name__ == "__main__":
    main()

"""
Insert Sociodemographic Imputations into DuckDB

Reads Feather files generated by 02_impute_sociodemographic.R and inserts
imputed values into DuckDB tables.

Usage:
    python scripts/imputation/02b_insert_sociodem_imputations.py
"""

import sys
from pathlib import Path
import pandas as pd

# Add project root to path
# __file__ is scripts/imputation/ne25/02b_insert_sociodem_imputations.py
# parent = ne25/, parent.parent = imputation/, parent.parent.parent = scripts/, parent.parent.parent.parent = project_root
project_root = Path(__file__).resolve().parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from python.db.connection import DatabaseManager
from python.imputation.config import get_study_config, get_sociodem_variables, get_table_prefix


def load_feather_files(feather_dir: Path, variable_name: str, n_imputations: int):
    """
    Load Feather files for a single variable across all imputations

    Parameters
    ----------
    feather_dir : Path
        Directory containing Feather files
    variable_name : str
        Name of variable (e.g., "sex", "raceG")
    n_imputations : int
        Number of imputations to load (M)

    Returns
    -------
    dict
        Dictionary mapping imputation_m to DataFrame
    """
    # Pattern: {variable}_m{m}.feather (e.g., sex_m1.feather)
    pattern = f"{variable_name}_m*.feather"
    feather_files = sorted(feather_dir.glob(pattern))

    if len(feather_files) == 0:
        raise FileNotFoundError(
            f"No Feather files found for variable '{variable_name}' in {feather_dir}\n"
            f"Expected pattern: {pattern}\n"
            f"Run: Rscript scripts/imputation/02_impute_sociodemographic.R first"
        )

    imputations = {}

    for f in feather_files:
        # Extract m from filename (e.g., female_m1.feather -> 1, educ_mom_m1.feather -> 1)
        # Use regex to match the pattern: variable_name_m{digit}.feather
        import re
        match = re.search(r'_m(\d+)$', f.stem)
        if not match:
            raise ValueError(f"Could not extract imputation number from filename: {f.name}")
        m = int(match.group(1))
        df = pd.read_feather(f)

        # Validate columns
        expected_cols = {'study_id', 'pid', 'record_id', 'imputation_m', variable_name}
        if not expected_cols.issubset(df.columns):
            raise ValueError(
                f"Missing columns in {f.name}. Expected: {expected_cols}, Got: {set(df.columns)}"
            )

        imputations[m] = df

    if len(imputations) != n_imputations:
        print(f"  [WARN] Expected {n_imputations} files, found {len(imputations)} for {variable_name}")

    return imputations


def insert_variable_imputations(
    db: DatabaseManager,
    variable_name: str,
    imputations_dict: dict,
    study_id: str = "ne25"
):
    """
    Insert imputations for a single variable into database

    Parameters
    ----------
    db : DatabaseManager
        Database connection manager
    variable_name : str
        Name of variable (e.g., "sex", "raceG", etc.)
    imputations_dict : dict
        Dictionary mapping imputation_m to DataFrame (already filtered to this variable)
    study_id : str
        Study identifier

    Returns
    -------
    int
        Number of rows inserted
    """
    print(f"\n[INFO] Inserting {variable_name} imputations...")

    table_prefix = get_table_prefix(study_id)
    table_name = f"{table_prefix}_{variable_name}"

    # Combine all imputations for this variable
    all_imputations = []

    for m, df in imputations_dict.items():
        if len(df) == 0:
            print(f"  [WARN] No imputed values for {variable_name} in m={m}")
            continue

        # Validate expected columns
        if variable_name not in df.columns:
            raise ValueError(f"Column '{variable_name}' not found in imputation m={m}")

        # Select only needed columns
        var_df = df[['study_id', 'pid', 'record_id', 'imputation_m', variable_name]].copy()

        all_imputations.append(var_df)

    if len(all_imputations) == 0:
        print(f"  [SKIP] No imputed values found for {variable_name}")
        return 0

    # Combine all imputations
    combined_df = pd.concat(all_imputations, ignore_index=True)

    print(f"  Combined {len(combined_df)} rows across {len(imputations_dict)} imputations")

    # Insert into database
    with db.get_connection() as conn:
        # Clear existing imputations for this study
        conn.execute(f"""
            DELETE FROM {table_name}
            WHERE study_id = '{study_id}'
        """)

        # Insert new imputations
        conn.execute(f"""
            INSERT INTO {table_name}
            SELECT * FROM combined_df
        """)

    print(f"  [OK] Inserted {len(combined_df)} rows into {table_name}")

    return len(combined_df)


def update_metadata(
    db: DatabaseManager,
    study_id: str,
    variable_name: str,
    n_imputations: int,
    n_records_imputed: int,
    imputation_method: str
):
    """
    Update or insert metadata for imputed variable

    Parameters
    ----------
    study_id : str
        Study identifier (e.g., "ne25")
    db : DatabaseManager
        Database connection manager
    variable_name : str
        Name of imputed variable
    n_imputations : int
        Number of imputations generated
    n_records_imputed : int
        Number of records imputed
    imputation_method : str
        Method used (e.g., "cart", "rf")
    """
    with db.get_connection() as conn:
        # Check if metadata exists
        exists = conn.execute(f"""
            SELECT COUNT(*) as count
            FROM imputation_metadata
            WHERE study_id = '{study_id}' AND variable_name = '{variable_name}'
        """).df()

        if exists['count'].iloc[0] > 0:
            # Update existing
            conn.execute(f"""
                UPDATE imputation_metadata
                SET n_imputations = {n_imputations},
                    imputation_method = '{imputation_method}',
                    created_date = CURRENT_TIMESTAMP,
                    created_by = '02b_insert_sociodem_imputations.py',
                    notes = 'Imputed via mice package for {n_records_imputed} records with missing values'
                WHERE study_id = '{study_id}' AND variable_name = '{variable_name}'
            """)
        else:
            # Insert new
            conn.execute(f"""
                INSERT INTO imputation_metadata
                (study_id, variable_name, n_imputations, imputation_method, created_by, notes)
                VALUES (
                    '{study_id}',
                    '{variable_name}',
                    {n_imputations},
                    '{imputation_method}',
                    '02b_insert_sociodem_imputations.py',
                    'Imputed via mice package for {n_records_imputed} records with missing values'
                )
            """)


def main():
    """
    Main insertion workflow
    """
    print("Insert Sociodemographic Imputations into DuckDB")
    print("=" * 60)

    # Load study-specific configuration
    study_id = "ne25"
    config = get_study_config(study_id)
    sociodem_vars = get_sociodem_variables()

    print(f"Configuration:")
    print(f"  Study: {config['study_name']}")
    print(f"  Study ID: {study_id}")
    print(f"  Number of imputations (M): {config['n_imputations']}")
    print(f"  Variables: {', '.join(sociodem_vars)}")
    print(f"  Database: {config['database']['db_path']}")

    # Connect to database
    db = DatabaseManager()
    print(f"\n[OK] Connected to database")

    # Feather files directory (study-specific)
    feather_dir = project_root / config['data_dir'] / "sociodem_feather"

    # Add derived variable (fplcat)
    all_vars = sociodem_vars + ["fplcat"]

    # Get imputation methods from config
    mice_methods = config['sociodemographic']['mice_method']

    # Process each variable
    results = {}

    for var in all_vars:
        print(f"\n[INFO] Processing variable: {var}")

        # Load Feather files for this variable
        try:
            imputations_dict = load_feather_files(feather_dir, var, config['n_imputations'])
            print(f"  [OK] Loaded {len(imputations_dict)} imputation files for {var}")
        except FileNotFoundError as e:
            print(f"  [ERROR] {e}")
            results[var] = 0
            continue

        # Insert into database
        n_inserted = insert_variable_imputations(
            db=db,
            variable_name=var,
            imputations_dict=imputations_dict,
            study_id='ne25'
        )
        results[var] = n_inserted

        # Update metadata
        if var in mice_methods:
            method = mice_methods[var]
        elif var == "fplcat":
            method = "derived"
        else:
            method = "unknown"

        # Calculate number of unique records imputed
        all_records = []
        for m, df in imputations_dict.items():
            all_records.extend(df['record_id'].unique())
        n_unique_records = len(set(all_records))

        update_metadata(db, study_id, var, config['n_imputations'], n_unique_records, method)

    # Summary
    print("\n" + "=" * 60)
    print("Insertion Summary:")

    total_rows = 0
    for var, n_rows in results.items():
        print(f"  {var}: {n_rows} rows")
        total_rows += n_rows

    print(f"\nTotal rows inserted: {total_rows}")
    print("\n[OK] Sociodemographic imputation insertion complete!")

    print("\nNext steps:")
    print("  1. Validate: python -m python.imputation.helpers")
    print("  2. Query: Use get_completed_dataset(m=1, variables=['sex', 'raceG'])")


if __name__ == "__main__":
    main()
